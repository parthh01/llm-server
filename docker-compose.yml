version: "3.9"
services:
  ollama: 
    build: 
        dockerfile: Dockerfile.ollama
    container_name: ollama
    image: ollama_local
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #       - driver: nvidia
    #         count: 1
    #         capabilities: [gpu]
  
  postgres:
      image: postgres:14-alpine
      volumes:
        - litellmpg:/var/lib/postgresql/data
      environment:
        - POSTGRES_PASSWORD=${PGPASSWORD}
        - POSTGRES_USER=${PGUSER}
        - POSTGRES_DB=${PGDB}
  ollamastartup:
    build: 
        dockerfile: Dockerfile.ollamastartup
    depends_on: 
        - ollama
    restart: "no"
  litellm:
    env_file: .env
    depends_on: 
        - postgres
    build: 
        dockerfile: Dockerfile.litellm
    ports:
      - "8000:8000" # Map the container port to the host, change the host port if necessary
    volumes:
      - ./.env:/app/.env
    # You can change the port or number of workers as per your requirements or pass any new supported CLI augument. Make sure the port passed here matches with the container port defined above in `ports` value
    environment:
      - DATABASE_URL=postgresql://${PGUSER}:${PGPASSWORD}@postgres:5432/${PGDB}
  webui: 
    image: ghcr.io/ollama-webui/ollama-webui:main
    volumes: 
      - webui:/app/backend/data
    environment:
      - OPENAPI_BASE_URL:http://litellm:8000
  nginx:
    depends_on:
        - litellm 
    build:
        dockerfile: Dockerfile.reverseproxy
        args:
          BASIC_USERNAME: ${BASIC_USERNAME}
          BASIC_PASSWORD: ${BASIC_PASSWORD}
    container_name: reverseproxy
    image: nginx_local
    ports: 
        - "80:80"
        - "443:443"
    # environment:
    #     BASIC_USERNAME: admin
    #     BASIC_PASSWORD: admin
volumes:   # add this section
  webui:
  litellmpg: 
