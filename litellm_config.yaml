model_list:
  - model_name: llama2
    litellm_params:
      model: ollama/llama2
      api_base: http://ollama:11434
      headers: {
        "HTTP-Referer": "litellm.ai",  
        "X-Title": "LiteLLM Server"
      }
  - model_name: phi
    litellm_params:
      model: ollama/phi
      api_base: http://ollama:11434
      headers: {
        "HTTP-Referer": "litellm.ai",
        "X-Title": "LiteLLM Server"
      }
  - model_name: mixtral
    litellm_params:
      model: ollama/mixtral
      api_base: http://ollama:11434
      headers: {
        "HTTP-Referer": "litellm.ai",
        "X-Title": "LiteLLM Server"
      }
general_settings: 
  master_key: sk-6786 # [OPTIONAL] if set all calls to proxy will require either this key or a valid generated token
  database_url: "postgresql://litellm:litellm@postgres:5432/litellm"
